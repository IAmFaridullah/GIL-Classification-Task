{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To load dataset from kaggle to google colab, We have to first create our api token in our kaggle account, download its json file and then upload that file to colab. That api token will allow us to load dataset from kaggle to google colab. Below command is used to copy uploaded token file to kaggle directory on colab."
      ],
      "metadata": {
        "id": "7f3Fw4rkXe8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "cQrZQEtTMlYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By running the below code, The first line will start downloading the dataset in .zip format. The second line is to extract the dataset from zip file."
      ],
      "metadata": {
        "id": "VnJ1Yqy5c7Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d alxmamaev/flowers-recognition\n",
        "!unzip -q flowers-recognition.zip -d flower-dataset"
      ],
      "metadata": {
        "id": "I-mk_SV4NE0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Below code box, we imported all the necessary libraries or modules that we will use in code later."
      ],
      "metadata": {
        "id": "Fdx8YKCfd0f2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tvu1iGgABtMa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the code of our model. Since we have a very small dataset, we cannot achieve good accuracy with this dataset. So to achieve a good accuracy i had to apply some techniques to deal with the problem of having small dataset. Some of the techniques are Data augmentation, Transfer learning with resnet50 architecture, regularization etc. Overall accuracy that i achieved with all of the techniques mentioned is **90%**."
      ],
      "metadata": {
        "id": "0W2tOtRvehuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomRotation(degrees=30),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = ImageFolder(root='flower-dataset/flowers', transform=transform)\n",
        "\n",
        "# Define the sizes of train and test splits\n",
        "train_size = int(0.8 * len(dataset))  # 80% for training\n",
        "test_size = len(dataset) - train_size  # Remaining 20% for testing\n",
        "\n",
        "# Divide the dataset into train and test splits\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "\n",
        "# Create data loaders for train and test sets\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Load a pre-trained ResNet-18 model and modify it\n",
        "resnet_model = models.resnet50(pretrained=True)\n",
        "\n",
        "num_classes = len(dataset.classes)\n",
        "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet_model.parameters(), lr=0.0001)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "resnet_model.to(device)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    resnet_model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = resnet_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "resnet_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "W7oqnINTbdjT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}